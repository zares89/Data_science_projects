{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.10.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"none","dataSources":[{"sourceId":3004,"databundleVersionId":861823,"sourceType":"competition"}],"dockerImageVersionId":30698,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n    \nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","execution":{"iopub.status.busy":"2024-05-10T17:27:52.447813Z","iopub.execute_input":"2024-05-10T17:27:52.448302Z","iopub.status.idle":"2024-05-10T17:27:52.995609Z","shell.execute_reply.started":"2024-05-10T17:27:52.448264Z","shell.execute_reply":"2024-05-10T17:27:52.994537Z"},"trusted":true},"execution_count":2,"outputs":[{"name":"stdout","text":"/kaggle/input/digit-recognizer/sample_submission.csv\n/kaggle/input/digit-recognizer/train.csv\n/kaggle/input/digit-recognizer/test.csv\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We will study the MNIST dataset with conventional machine learning methods as well as deep learning methods.","metadata":{}},{"cell_type":"markdown","source":"### Loading Data\n","metadata":{}},{"cell_type":"code","source":"%matplotlib inline\nimport sys\nimport matplotlib.pyplot as plt \nimport gzip, os\nimport numpy as np\nfrom scipy.stats import multivariate_normal","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:27:55.976641Z","iopub.execute_input":"2024-05-10T17:27:55.977224Z","iopub.status.idle":"2024-05-10T17:27:56.596035Z","shell.execute_reply.started":"2024-05-10T17:27:55.977188Z","shell.execute_reply":"2024-05-10T17:27:56.594979Z"},"trusted":true},"execution_count":3,"outputs":[]},{"cell_type":"code","source":"train = pd.read_csv(\"/kaggle/input/digit-recognizer/train.csv\")\ntest = pd.read_csv(\"/kaggle/input/digit-recognizer/test.csv\")\ntargets_numpy = train.label.values\nfeatures_numpy = train.loc[:,train.columns != \"label\"].values\n#test_label_numpy = test.label.values\ntest_features_numpy = test.loc[:,test.columns != \"label\"].values","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:28:03.629350Z","iopub.execute_input":"2024-05-10T17:28:03.629756Z","iopub.status.idle":"2024-05-10T17:28:10.794695Z","shell.execute_reply.started":"2024-05-10T17:28:03.629726Z","shell.execute_reply":"2024-05-10T17:28:10.793542Z"},"trusted":true},"execution_count":4,"outputs":[]},{"cell_type":"code","source":"sample_submission = pd.read_csv('/kaggle/input/digit-recognizer/sample_submission.csv')","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:28:19.383072Z","iopub.execute_input":"2024-05-10T17:28:19.383473Z","iopub.status.idle":"2024-05-10T17:28:19.404925Z","shell.execute_reply.started":"2024-05-10T17:28:19.383428Z","shell.execute_reply":"2024-05-10T17:28:19.403961Z"},"trusted":true},"execution_count":5,"outputs":[]},{"cell_type":"code","source":"sample_submission","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:29:14.094033Z","iopub.execute_input":"2024-05-10T17:29:14.094402Z","iopub.status.idle":"2024-05-10T17:29:14.115303Z","shell.execute_reply.started":"2024-05-10T17:29:14.094374Z","shell.execute_reply":"2024-05-10T17:29:14.113930Z"},"trusted":true},"execution_count":7,"outputs":[{"execution_count":7,"output_type":"execute_result","data":{"text/plain":"       ImageId  Label\n0            1      0\n1            2      0\n2            3      0\n3            4      0\n4            5      0\n...        ...    ...\n27995    27996      0\n27996    27997      0\n27997    27998      0\n27998    27999      0\n27999    28000      0\n\n[28000 rows x 2 columns]","text/html":"<div>\n<style scoped>\n    .dataframe tbody tr th:only-of-type {\n        vertical-align: middle;\n    }\n\n    .dataframe tbody tr th {\n        vertical-align: top;\n    }\n\n    .dataframe thead th {\n        text-align: right;\n    }\n</style>\n<table border=\"1\" class=\"dataframe\">\n  <thead>\n    <tr style=\"text-align: right;\">\n      <th></th>\n      <th>ImageId</th>\n      <th>Label</th>\n    </tr>\n  </thead>\n  <tbody>\n    <tr>\n      <th>0</th>\n      <td>1</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>1</th>\n      <td>2</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>2</th>\n      <td>3</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>3</th>\n      <td>4</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>4</th>\n      <td>5</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>...</th>\n      <td>...</td>\n      <td>...</td>\n    </tr>\n    <tr>\n      <th>27995</th>\n      <td>27996</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27996</th>\n      <td>27997</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27997</th>\n      <td>27998</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27998</th>\n      <td>27999</td>\n      <td>0</td>\n    </tr>\n    <tr>\n      <th>27999</th>\n      <td>28000</td>\n      <td>0</td>\n    </tr>\n  </tbody>\n</table>\n<p>28000 rows Ã— 2 columns</p>\n</div>"},"metadata":{}}]},{"cell_type":"code","source":"def displaychar(image):\n    plt.imshow(np.reshape(image, (28,28)), cmap=plt.cm.gray)\n    plt.axis('off')\n    plt.show()","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:29:16.961499Z","iopub.execute_input":"2024-05-10T17:29:16.961873Z","iopub.status.idle":"2024-05-10T17:29:16.968183Z","shell.execute_reply.started":"2024-05-10T17:29:16.961845Z","shell.execute_reply":"2024-05-10T17:29:16.966661Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"code","source":"displaychar(features_numpy[7])","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:29:18.332634Z","iopub.execute_input":"2024-05-10T17:29:18.333255Z","iopub.status.idle":"2024-05-10T17:29:18.448089Z","shell.execute_reply.started":"2024-05-10T17:29:18.333218Z","shell.execute_reply":"2024-05-10T17:29:18.446347Z"},"trusted":true},"execution_count":9,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"code","source":"train_digits, train_counts = np.unique(targets_numpy, return_counts=True)\nprint(dict(zip(train_digits, train_counts)))","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:29:20.642076Z","iopub.execute_input":"2024-05-10T17:29:20.642495Z","iopub.status.idle":"2024-05-10T17:29:20.650218Z","shell.execute_reply.started":"2024-05-10T17:29:20.642459Z","shell.execute_reply":"2024-05-10T17:29:20.649029Z"},"trusted":true},"execution_count":10,"outputs":[{"name":"stdout","text":"{0: 4132, 1: 4684, 2: 4177, 3: 4351, 4: 4072, 5: 3795, 6: 4137, 7: 4401, 8: 4063, 9: 4188}\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### 1. Data preprocessing\nWe tried to standardize the data to speed up computations. However, it seems like some features have zero value in the entire dataset. I guess we can remove those features, standardize the data, and perform machine learning.","metadata":{}},{"cell_type":"code","source":"features_numpy = features_numpy.astype(np.float32)\nmean_features = np.mean(features_numpy, axis=0).astype(np.float32)\nstd_features = np.std(features_numpy, axis=0).astype(np.float32)\nfeatures_numpy -= mean_features\nfeatures_numpy /= std_features\n","metadata":{"execution":{"iopub.status.busy":"2024-05-07T04:49:57.732700Z","iopub.execute_input":"2024-05-07T04:49:57.733150Z","iopub.status.idle":"2024-05-07T04:49:57.960187Z","shell.execute_reply.started":"2024-05-07T04:49:57.733115Z","shell.execute_reply":"2024-05-07T04:49:57.959354Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stderr","text":"/tmp/ipykernel_33/3787671715.py:5: RuntimeWarning: invalid value encountered in divide\n  features_numpy /= std_features\n","output_type":"stream"}]},{"cell_type":"code","source":"\ncondition = (np.std(features_numpy, axis=0).astype(np.float32) == 0) & (np.mean(features_numpy, axis=0).astype(np.float32) == 0)\nnp.where(condition)\n","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:37:58.860774Z","iopub.execute_input":"2024-05-10T17:37:58.861201Z","iopub.status.idle":"2024-05-10T17:37:59.131071Z","shell.execute_reply.started":"2024-05-10T17:37:58.861170Z","shell.execute_reply":"2024-05-10T17:37:59.129895Z"},"trusted":true},"execution_count":21,"outputs":[{"execution_count":21,"output_type":"execute_result","data":{"text/plain":"(array([  0,   1,   2,   3,   4,   5,   6,   7,   8,   9,  10,  11,  16,\n         17,  18,  19,  20,  21,  22,  23,  24,  25,  26,  27,  28,  29,\n         30,  31,  52,  53,  54,  55,  56,  57,  82,  83,  84,  85, 111,\n        112, 139, 140, 141, 168, 196, 392, 420, 421, 448, 476, 532, 560,\n        644, 645, 671, 672, 673, 699, 700, 701, 727, 728, 729, 730, 731,\n        754, 755, 756, 757, 758, 759, 760, 780, 781, 782, 783]),)"},"metadata":{}}]},{"cell_type":"code","source":"np.where(features_numpy[:,12]==0)","metadata":{"execution":{"iopub.status.busy":"2024-05-10T17:43:03.720372Z","iopub.execute_input":"2024-05-10T17:43:03.720782Z","iopub.status.idle":"2024-05-10T17:43:03.729598Z","shell.execute_reply.started":"2024-05-10T17:43:03.720753Z","shell.execute_reply":"2024-05-10T17:43:03.728309Z"},"trusted":true},"execution_count":40,"outputs":[{"execution_count":40,"output_type":"execute_result","data":{"text/plain":"(array([    0,     1,     2, ..., 41997, 41998, 41999]),)"},"metadata":{}}]},{"cell_type":"code","source":"# mean_features = np.mean(features_numpy, axis=0).astype(np.float32)\n# std_features = np.std(features_numpy, axis=0).astype(np.float32)\n# features_numpy -= mean_features\n# features_nump /= std_features\n# print(features_numpy_tmp[0,300])\n","metadata":{"execution":{"iopub.status.busy":"2024-05-05T05:29:22.970005Z","iopub.execute_input":"2024-05-05T05:29:22.970363Z","iopub.status.idle":"2024-05-05T05:29:22.978721Z","shell.execute_reply.started":"2024-05-05T05:29:22.970339Z","shell.execute_reply":"2024-05-05T05:29:22.977363Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"# np_arr = np.array([[4.2,2,3],[2,3.5,10.5],[2,3.5,10.6]]).astype(np.float32)\n# print(np_arr)\n# mean_np = np.mean(np_arr, axis=0)\n# print(\"mean is {}\".format(mean_np))\n# std_np = np.std(np_arr, axis=0)\n# print(\"std is {}\".format(std_np))\n# np_arr -= mean_np\n# print(np_arr)\n# np_arr /= std_np\n# print(np_arr)\n# print(np.mean(np_arr, axis=0))\n# print(np.std(np_arr, axis=0))","metadata":{"execution":{"iopub.status.busy":"2024-05-05T07:18:49.811043Z","iopub.execute_input":"2024-05-05T07:18:49.811440Z","iopub.status.idle":"2024-05-05T07:18:49.823977Z","shell.execute_reply.started":"2024-05-05T07:18:49.811412Z","shell.execute_reply":"2024-05-05T07:18:49.822614Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"Here, we are going to perform kNN. Then we will perform generative gaussian models and compare.","metadata":{}},{"cell_type":"markdown","source":"# Fit Gaussian Generative Models to Training Data\n\nWe define a function that fits multivariate gaussian functions to the training data. This function returns the mean values, the covariance matrices, and the probability of each label (0,1,2,...9) in the training data set. Because the data is large, it is most likely that the covariance matrix is singular. If we set allow_singular to 'True' in the multivariate_gaussian module, the pseudo-inverse of the covariance matrix will be calculated. First, we try this method. Then, we use a regularization method in which a non-zero regularization costant C is added to the covariance matrix to make it non-singular. We will see which one has a better prediction accuracy.","metadata":{}},{"cell_type":"code","source":"def fit_generative_model(x,y):\n    \n    k = 10  # labels 0,1,...,k-1\n    d = (x.shape)[1]  # number of features\n    mu = np.zeros((k,d))\n    sigma = np.zeros((k,d,d))\n    pi = np.zeros(k)\n    x_size = x.shape[0]\n    train_size = round(x_size * 0.99)\n    print(\"Training size is {} out of total {} data point\".format(train_size, x_size))\n    x_train = x\n    y_train = y     \n    # Initializing the optimizition for c constant\n    c = 0 # Errors  c={100000:0.4, 1000: 0.055,  10000: 0.047, 5000: 0.039} * When c is too large the error rapidly goes up\n    gen_tresh = 0.05\n\n    while True:\n        for label in range(k):\n            indices = (y_train == label)\n            mu[label] = np.mean(x_train[indices,:], axis = 0)\n            sigma[label] = np.cov(x_train[indices,:], rowvar=0, bias=1)\n            sigma[label] += c * np.identity(d)\n            pi[label] = np.sum(indices)\n\n#         pi = pi / (x_train.shape)[0]\n#         # Test the covariance matrix for c optimization\n#         score = np.zeros((x_validation.shape[0],k+1))\n#         for i in range(0,nt):\n#             for label in range(k):\n#                 score[i, label] = np.log(pi[label]) + \\\n#             multivariate_normal.logpdf(x_validation[i,:], mean=mu[label,:], cov=sigma[label])\n#         predictions = np.argmax(score, axis=1)\n#         err = np.sum(predictions != y_validation) / nt\n#         if err < gen_thresh:\n#             print(\"Final error rate is {}\".format(err))\n#             break\n#         else:\n#             print(\"Error is too large: {}\".format(err))\n#             c /= 2\n        break\n    \n    # Halt and return parameters\n    return mu, sigma, pi","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:08:36.008287Z","iopub.execute_input":"2024-05-08T22:08:36.008712Z","iopub.status.idle":"2024-05-08T22:08:36.019910Z","shell.execute_reply.started":"2024-05-08T22:08:36.008679Z","shell.execute_reply":"2024-05-08T22:08:36.018503Z"},"trusted":true},"execution_count":7,"outputs":[]},{"cell_type":"code","source":"mu, sigma, pi = fit_generative_model(features_numpy,targets_numpy)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T17:57:59.168678Z","iopub.execute_input":"2024-05-08T17:57:59.169104Z","iopub.status.idle":"2024-05-08T17:58:00.851851Z","shell.execute_reply.started":"2024-05-08T17:57:59.169072Z","shell.execute_reply":"2024-05-08T17:58:00.850630Z"},"trusted":true},"execution_count":8,"outputs":[{"name":"stdout","text":"Training size is 41580 out of total 42000 data point\n","output_type":"stream"}]},{"cell_type":"markdown","source":"We can now calculate the training error based on the generative gaussian models and allowing the calculation of the seudo-inverse and seudo-determenent of the covariance matrix. (ref: https://en.wikipedia.org/wiki/Multivariate_normal_distribution#Degenerate_case) ","metadata":{}},{"cell_type":"code","source":"# from scipy.stats import multivariate_normal\n\n# k = 10 \n# score_digit = np.zeros((features_numpy.shape[0], k))\n# for i in range(k):\n#     rv = multivariate_normal(mean=mu[i], cov= sigma[i])\n#     for j in range(score_digit.shape[0]):\n#         score_digit[j][i] = rv.logpdf(features_numpy[j,:]) + np.log(pi[i])\n# predictions = np.argmax(score_digit, axis=1)\n# errors = np.sum(predictions != targets_numpy) / len(targets_numpy)\n# print(\"The training error rate is: \" + str(errors))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T20:39:29.314515Z","iopub.execute_input":"2024-05-07T20:39:29.315459Z","iopub.status.idle":"2024-05-07T20:41:29.708009Z","shell.execute_reply.started":"2024-05-07T20:39:29.315424Z","shell.execute_reply":"2024-05-07T20:41:29.706918Z"},"trusted":true},"execution_count":12,"outputs":[{"name":"stdout","text":"The training error rate is: 0.1461904761904762\n","output_type":"stream"}]},{"cell_type":"markdown","source":"The training error is high. Why? Now, we try adding the regularization constant times the identity matrix to the covariance matrix.","metadata":{}},{"cell_type":"code","source":"# from scipy.stats import multivariate_normal\n\n# k = 10 \n# d = features_numpy.shape[1]\n# c = 4000\n# score_digit = np.zeros((features_numpy.shape[0], k))\n# for i in range(k):\n#     sigma[i] += c * np.identity(d)\n#     rv = multivariate_normal(mean=mu[i], cov= sigma[i])\n#     for j in range(score_digit.shape[0]):\n#         score_digit[j][i] = rv.logpdf(features_numpy[j,:]) + np.log(pi[i])\n# predictions = np.argmax(score_digit, axis=1)\n# errors = np.sum(predictions != targets_numpy) / len(targets_numpy)\n# print(\"The training error rate is: \" + str(errors))","metadata":{"execution":{"iopub.status.busy":"2024-05-07T20:56:38.207202Z","iopub.execute_input":"2024-05-07T20:56:38.208005Z","iopub.status.idle":"2024-05-07T20:58:02.612211Z","shell.execute_reply.started":"2024-05-07T20:56:38.207970Z","shell.execute_reply":"2024-05-07T20:58:02.611033Z"},"trusted":true},"execution_count":14,"outputs":[{"name":"stdout","text":"The training error rate is: 0.03907142857142857\n","output_type":"stream"}]},{"cell_type":"markdown","source":"After some trial and error, we get a relatively small error through regularizing the covariance matrix. Based on this, we calculate the predictions for the test set:","metadata":{}},{"cell_type":"code","source":"# from scipy.stats import multivariate_normal\n\n# k = 10 \n# score_digit = np.zeros((test_features_numpy.shape[0], k))\n# for i in range(k):\n#     rv = multivariate_normal(mean=mu[i], cov= sigma[i])\n#     for j in range(score_digit.shape[0]):\n#         score_digit[j][i] = rv.logpdf(test_features_numpy[j,:]) + np.log(pi[i])\n# predictions = np.argmax(score_digit, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-06T20:21:45.033460Z","iopub.execute_input":"2024-05-06T20:21:45.033996Z","iopub.status.idle":"2024-05-06T20:23:10.158967Z","shell.execute_reply.started":"2024-05-06T20:21:45.033954Z","shell.execute_reply":"2024-05-06T20:23:10.157390Z"},"trusted":true},"execution_count":13,"outputs":[]},{"cell_type":"markdown","source":"### Principal Component Analysis (PCA)","metadata":{}},{"cell_type":"markdown","source":"PCA can help with reducing the dimensions of the data through finding the eigen-values and eigen-vectors of the covariance matrix. This will cause a lower risk of overfitting. PCA can also help with removing those dimensions that are less useful and therefore reduce the noise in learning [?]. Lastly, reducing the dimenions will allow a faster computation. ","metadata":{}},{"cell_type":"code","source":"","metadata":{"execution":{"iopub.status.busy":"2024-05-08T06:53:55.501986Z","iopub.execute_input":"2024-05-08T06:53:55.502495Z","iopub.status.idle":"2024-05-08T06:53:55.509808Z","shell.execute_reply.started":"2024-05-08T06:53:55.502454Z","shell.execute_reply":"2024-05-08T06:53:55.508722Z"},"trusted":true},"execution_count":29,"outputs":[{"execution_count":29,"output_type":"execute_result","data":{"text/plain":"4684"},"metadata":{}}]},{"cell_type":"code","source":"from sklearn import datasets, decomposition\n\n\npca = decomposition.PCA(n_components=25)\nnlabels = 10\nnumber_of_points = features_numpy.shape[0]\npca.fit(features_numpy)\nresult_l = pca.transform(features_numpy) \n\n    \n","metadata":{"execution":{"iopub.status.busy":"2024-05-08T22:08:42.573549Z","iopub.execute_input":"2024-05-08T22:08:42.573912Z","iopub.status.idle":"2024-05-08T22:08:46.813050Z","shell.execute_reply.started":"2024-05-08T22:08:42.573885Z","shell.execute_reply":"2024-05-08T22:08:46.811366Z"},"trusted":true},"execution_count":8,"outputs":[]},{"cell_type":"markdown","source":"We write a new visualization function for PCA transformed data such that the vector components of each data lies in the range of 0 and 255.","metadata":{}},{"cell_type":"code","source":"def show_digit(x):\n    # Make sure all entries of x are in the range [0,255]\n    for i in range(784):\n        x[i] = max(0.0, x[i])\n        x[i] = min(255.0, x[i])\n    # Now display\n    plt.axis('off')\n    plt.imshow(x.reshape((28,28)), cmap=plt.cm.gray)\n    plt.show()\n    return","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:15:39.820036Z","iopub.execute_input":"2024-05-08T18:15:39.820444Z","iopub.status.idle":"2024-05-08T18:15:39.827286Z","shell.execute_reply.started":"2024-05-08T18:15:39.820413Z","shell.execute_reply":"2024-05-08T18:15:39.825894Z"},"trusted":true},"execution_count":11,"outputs":[]},{"cell_type":"code","source":"show_digit(pca.inverse_transform(result_l[2]))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:15:53.218654Z","iopub.execute_input":"2024-05-08T18:15:53.219406Z","iopub.status.idle":"2024-05-08T18:15:53.317712Z","shell.execute_reply.started":"2024-05-08T18:15:53.219368Z","shell.execute_reply":"2024-05-08T18:15:53.316460Z"},"trusted":true},"execution_count":14,"outputs":[{"output_type":"display_data","data":{"text/plain":"<Figure size 640x480 with 1 Axes>","image/png":"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"},"metadata":{}}]},{"cell_type":"markdown","source":"Now, we perform the scoring process for the PCA-transformed data","metadata":{"execution":{"iopub.status.busy":"2024-05-08T18:18:17.334309Z","iopub.execute_input":"2024-05-08T18:18:17.334723Z","iopub.status.idle":"2024-05-08T18:18:17.341906Z","shell.execute_reply.started":"2024-05-08T18:18:17.334689Z","shell.execute_reply":"2024-05-08T18:18:17.340241Z"}}},{"cell_type":"code","source":"from scipy.stats import multivariate_normal\nmu, sigma, pi = fit_generative_model(result_l,targets_numpy)\n\nk = 10 \nd = result_l.shape[1]\nc = 4000\nscore_digit = np.zeros((result_l.shape[0], k))\nfor i in range(k):\n    sigma[i] += c * np.identity(d)\n    rv = multivariate_normal(mean=mu[i], cov= sigma[i])\n    for j in range(score_digit.shape[0]):\n        score_digit[j][i] = rv.logpdf(result_l[j,:]) + np.log(pi[i])\npredictions = np.argmax(score_digit, axis=1)\nerrors = np.sum(predictions != targets_numpy) / len(targets_numpy)\nprint(\"The training error rate is: \" + str(errors))","metadata":{"execution":{"iopub.status.busy":"2024-05-08T06:47:27.020686Z","iopub.execute_input":"2024-05-08T06:47:27.021154Z","iopub.status.idle":"2024-05-08T06:47:49.602862Z","shell.execute_reply.started":"2024-05-08T06:47:27.021119Z","shell.execute_reply":"2024-05-08T06:47:49.601640Z"},"trusted":true},"execution_count":18,"outputs":[{"name":"stdout","text":"Training size is 41580 out of total 42000 data point\nThe training error rate is: 0.0445952380952381\n","output_type":"stream"}]},{"cell_type":"markdown","source":"Lastly, we calculate the predictions on the test set based on hte fitted PCA to training data.","metadata":{}},{"cell_type":"code","source":"k = 10\nresult_l = pca.transform(test_features_numpy)\nscore_digit = np.zeros((result_l.shape[0], k))\nfor i in range(k):\n    rv = multivariate_normal(mean=mu[i], cov= sigma[i])\n    for j in range(score_digit.shape[0]):\n        score_digit[j][i] = rv.logpdf(result_l[j,:]) + np.log(pi[i])\npredictions = np.argmax(score_digit, axis=1)","metadata":{"execution":{"iopub.status.busy":"2024-05-08T06:08:26.253105Z","iopub.execute_input":"2024-05-08T06:08:26.253549Z","iopub.status.idle":"2024-05-08T06:09:03.183383Z","shell.execute_reply.started":"2024-05-08T06:08:26.253513Z","shell.execute_reply":"2024-05-08T06:09:03.181772Z"},"trusted":true},"execution_count":12,"outputs":[]},{"cell_type":"code","source":"# Submission\n\n\nsample_submission['Label'] = predictions\nsample_submission.to_csv('submission.csv', index=False)\nprint(\"Your submission was successfully saved!\")","metadata":{"execution":{"iopub.status.busy":"2024-05-08T06:09:06.788996Z","iopub.execute_input":"2024-05-08T06:09:06.789798Z","iopub.status.idle":"2024-05-08T06:09:06.841925Z","shell.execute_reply.started":"2024-05-08T06:09:06.789746Z","shell.execute_reply":"2024-05-08T06:09:06.840425Z"},"trusted":true},"execution_count":13,"outputs":[{"name":"stdout","text":"Your submission was successfully saved!\n","output_type":"stream"}]},{"cell_type":"markdown","source":"### Kernel-PCA","metadata":{"execution":{"iopub.status.busy":"2024-05-08T07:30:14.201507Z","iopub.execute_input":"2024-05-08T07:30:14.201933Z","iopub.status.idle":"2024-05-08T07:30:14.210847Z","shell.execute_reply.started":"2024-05-08T07:30:14.201903Z","shell.execute_reply":"2024-05-08T07:30:14.209310Z"}}},{"cell_type":"markdown","source":"If the data is non-linear PCA is not gonna work well. Instead, we try Kernel-PCA (Ref: https://people.eecs.berkeley.edu/~wainwrig/stat241b/scholkopf_kernel.pdf)","metadata":{}},{"cell_type":"code","source":"kernel_pca = decomposition.KernelPCA(n_components=None, kernel=\"rbf\", gamma=10, fit_inverse_transform=True, alpha=0.1)\nkernel_pca.fit(features_numpy)\nresult_l = kernel_pca.transform(features_numpy) ","metadata":{"execution":{"iopub.status.busy":"2024-05-08T19:25:54.832449Z","iopub.execute_input":"2024-05-08T19:25:54.833327Z"},"trusted":true},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"show_digit(pca.inverse_transform(result_l[2]))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"code","source":"from scipy.stats import multivariate_normal\nmu, sigma, pi = fit_generative_model(result_l,targets_numpy)\n\nk = 10 \nd = result_l.shape[1]\nc = 4000\nscore_digit = np.zeros((result_l.shape[0], k))\nfor i in range(k):\n    sigma[i] += c * np.identity(d)\n    rv = multivariate_normal(mean=mu[i], cov= sigma[i])\n    for j in range(score_digit.shape[0]):\n        score_digit[j][i] = rv.logpdf(result_l[j,:]) + np.log(pi[i])\npredictions = np.argmax(score_digit, axis=1)\nerrors = np.sum(predictions != targets_numpy) / len(targets_numpy)\nprint(\"The training error rate is: \" + str(errors))","metadata":{},"execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Multi-class SVM","metadata":{}},{"cell_type":"markdown","source":"There is a notebook on the web that discusses Multi-class SVM in length (https://dmkothari.github.io/Machine-Learning-Projects/SVM_with_MNIST.html). I am not looking at it, and trying to experiment myself. Later on, I will look into that and see what I can learn","metadata":{}},{"cell_type":"code","source":"from sklearn.svm import SVC, LinearSVC\nfrom sklearn.model_selection import train_test_split\nfrom sklearn.model_selection import cross_val_score\n#X_train, X_test, y_train, y_test = train_test_split(features_numpy, targets_numpy, test_size=0.4, random_state=0)\nC_value = 10.0\nclf = LinearSVC(loss='hinge', multi_class='crammer_singer', C=C_value)\nscores = cross_val_score(clf, features_numpy, targets_numpy, cv=5)\n\n\n","metadata":{"execution":{"iopub.status.busy":"2024-05-09T17:03:31.871779Z","iopub.execute_input":"2024-05-09T17:03:31.872233Z","iopub.status.idle":"2024-05-09T19:38:20.241375Z","shell.execute_reply.started":"2024-05-09T17:03:31.872200Z","shell.execute_reply":"2024-05-09T19:38:20.239484Z"},"trusted":true},"execution_count":9,"outputs":[{"name":"stderr","text":"/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n/opt/conda/lib/python3.10/site-packages/sklearn/svm/_base.py:1244: ConvergenceWarning: Liblinear failed to converge, increase the number of iterations.\n  warnings.warn(\n","output_type":"stream"}]},{"cell_type":"code","source":"scores","metadata":{"execution":{"iopub.status.busy":"2024-05-09T20:09:08.816688Z","iopub.execute_input":"2024-05-09T20:09:08.817160Z","iopub.status.idle":"2024-05-09T20:09:08.826196Z","shell.execute_reply.started":"2024-05-09T20:09:08.817127Z","shell.execute_reply":"2024-05-09T20:09:08.824684Z"},"trusted":true},"execution_count":12,"outputs":[{"execution_count":12,"output_type":"execute_result","data":{"text/plain":"array([0.58535714, 0.58892857, 0.5925    , 0.59154762, 0.60583333])"},"metadata":{}}]},{"cell_type":"code","source":"","metadata":{},"execution_count":null,"outputs":[]}]}